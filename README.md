# MBTI Personality Prediction using NLP

Predict Myersâ€‘Briggs Type Indicator (MBTI) personality types from a userâ€™s text posts with classic Naturalâ€¯Languageâ€¯Processing and a Logistic Regression classifier.

---

## ðŸ“š Project Overview

This notebookâ€‘based project shows an *endâ€‘toâ€‘end* NLP workflow:

1. **Data Ingestion** â€“ Upload the popular MBTIâ€‘500 dataset (or any CSV with `posts` & `type` columns).
2. **Preâ€‘processing** â€“ Lowerâ€‘casing, link/emoji removal, stopâ€‘word filtering.
3. **Feature Extraction** â€“ TFâ€‘IDF (top 5â€¯000 nâ€‘grams).
4. **Modeling** â€“ Multiclass Logistic Regression.
5. **Evaluation** â€“ Accuracy & detailed classification report.
6. **Inference** â€“ `predict_mbti()` helper for new text.
7. **Visualization** â€“ Distribution of personality types.

> **Why Logistic Regression?**  It trains fast, is easy to interpret, and performs surprisingly well on sparse TFâ€‘IDF features. You can swap in SVM, XGBoost, or a transformer (e.g. BERT) later.

---

## ðŸ—‚ Dataset

* **Source:** [Kaggle â€“ MBTIÂ 500](https://www.kaggle.com/datasnaek/mbti-type) (50â€¯k+ Reddit/Forum posts labelled with 16 MBTI classes).
* **Columns**
  `type`Â â€“ MBTI label (e.g.Â INTP)
  `posts`Â â€“ Userâ€™s concatenated socialâ€‘media posts (pipeâ€‘separated).

Feel free to use any dataset with the same two columns â€“ the code is agnostic.

---

## ðŸ— QuickÂ Start (GoogleÂ Colab)

```python
!pip install nltk scikit-learn seaborn pandas

from google.colab import files
uploaded = files.upload()            # â¬†ï¸ upload your CSV

# run the rest of the notebook cells â€¦
```

The notebook prints training metrics, a sample prediction, and a barâ€‘chart of class counts.

> **Tip:** Colab has a free GPU, but this model is CPUâ€‘friendly.

---

## ðŸ”¨ Code Walkâ€‘through

| Step | Purpose              | Key Functions                                        |
| ---- | -------------------- | ---------------------------------------------------- |
| 1    | **Import libs**      | `pandas`, `nltk`, `sklearn`, `matplotlib`, `seaborn` |
| 2    | **Load data**        | `pd.read_csv()`                                      |
| 3    | **Clean text**       | `re.sub`, NLTK `stopwords`                           |
| 4    | **Encode labels**    | `LabelEncoder()`                                     |
| 5    | **Vectorize**        | `TfidfVectorizer(max_features=5000)`                 |
| 6    | **Train/Test split** | `train_test_split(test_size=0.2)`                    |
| 7    | **Train model**      | `LogisticRegression(max_iter=1000)`                  |
| 8    | **Evaluate**         | `classification_report`, `accuracy_score`            |
| 9    | **Predict new text** | `predict_mbti()` helper                              |
| 10   | **Visualize**        | `seaborn.countplot()`                                |

---

## ðŸš€ Using `predict_mbti()`

```python
sample = "I enjoy deep conversations about abstract topics and often reflect on my thoughts."
print(predict_mbti(sample))  # âžœ e.g.Â "INFJ"
```

Embed this function into a Flask / FastAPI / Streamlit app to serve live predictions.

---

## ðŸ”„ Extending the Project

* **Better Features** â€“ Nâ€‘grams, characterâ€‘grams, or transformer embeddings.
* **Hyperâ€‘parameter Tuning** â€“ `GridSearchCV` for C, penalty, and class weights.
* **Model Zoo** â€“ Compare SVM, Random Forest, or fineâ€‘tuned BERT.
* **Explainability** â€“ Show top TFâ€‘IDF weights per class with `eli5`.
* **Web App** â€“ Add a React or Next.js frontâ€‘end (Shashankâ€™s specialty!).

---

## ðŸ–¼ Example Output

<div align="center">
  <img src="" width="480" ![WhatsApp Image 2025-05-27 at 12 46 58 PM](https://github.com/user-attachments/assets/84d7a652-d190-46fe-b636-38b312cc29dd)

</div>

---

## ðŸ“‘ Requirements

* PythonÂ 3.8+
* pandas, numpy, scikitâ€‘learn, nltk, seaborn, matplotlib

> ```bash
> pip install -r requirements.txt
> ```

Create *requirements.txt* via `pip freeze > requirements.txt` after testing.

---
